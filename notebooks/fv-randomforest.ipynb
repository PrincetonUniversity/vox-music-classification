{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Random Forest multiclass regression with default (3, 3) parameter FV on only the MFCC features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing FVs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import scipy.io as spio\n",
    "import numpy as np\n",
    "from os.path import join, isdir, isfile\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DATA_DIR = '../data'\n",
    "# 'file_name' 'class_name' 'class' 'eng' 'mfc' 'chroma' 't'\n",
    "# 'keystrength' 'brightness' 'zerocross' 'roughness' 'inharmonic' 'hcdf'\n",
    "#\n",
    "FVs = join(DATA_DIR, 'FV.mat')\n",
    "LBs = join(DATA_DIR, 'LB.mat')\n",
    "if not isfile(FVs) or not isfile(LBs):\n",
    "    print('Generating Fisher Vectors')\n",
    "    !matlab -nodisplay -nosplash -nodesktop -r \"run('../tools/FV_concat.m');exit;\"\n",
    "else:\n",
    "    print('Using existing FVs')\n",
    "\n",
    "mfcc = np.transpose(spio.loadmat(FVs)['FV'])\n",
    "labels = spio.loadmat(LBs)['LB'][0]\n",
    "N = mfcc.shape[0]\n",
    "\n",
    "p = np.random.permutation(N)\n",
    "mfcc = mfcc[p]\n",
    "labels = labels[p]\n",
    "\n",
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import scipy.io as spio\n",
    "import numpy as np\n",
    "from os.path import join, isdir, isfile\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "DATA_DIR = '../generated-fv/'\n",
    "FVs = join(DATA_DIR, 'FV3-3.mat')\n",
    "LBs = join(DATA_DIR, 'LB.mat')\n",
    "mfcc = np.transpose(spio.loadmat(FVs)['FV'])\n",
    "labels = spio.loadmat(LBs)['LB'][0]\n",
    "N = mfcc.shape[0]\n",
    "\n",
    "p = np.random.permutation(N)\n",
    "mfcc = mfcc[p]\n",
    "labels = labels[p]\n",
    "\n",
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "means in range [-0.0210, 0.0095]\n",
      "std in range [0.0201, 0.0618]\n",
      "norm. means in range [-0.0000, 0.0000]\n",
      "norm. std in range [1.0000, 1.0000]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(800, 960)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trN = int(0.8 * N)\n",
    "teN = N - trN\n",
    "trX, trY = mfcc[:trN], labels[:trN]\n",
    "teX, teY = mfcc[-teN:], labels[-teN:]\n",
    "len(set(trY))\n",
    "\n",
    "means = np.mean(trX, axis=0)\n",
    "stddevs = np.std(trX, axis=0)\n",
    "\n",
    "def summary(x):\n",
    "    return '[{:.4f}, {:.4f}]'.format(np.ndarray.min(x), np.ndarray.max(x))\n",
    "print('means in range', summary(means))\n",
    "print('std in range', summary(stddevs))\n",
    "\n",
    "# Whitened data\n",
    "def adjust(x): return (x - means[None, :]) / stddevs[None, :]\n",
    "trXadj = adjust(trX)\n",
    "teXadj = adjust(teX)\n",
    "\n",
    "print('norm. means in range', summary(np.mean(trXadj, axis=0)))\n",
    "print('norm. std in range', summary(np.std(trXadj, axis=0)))\n",
    "trX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth 5, learners 100, score 0.578926282051282\n",
      "depth 5, learners 200, score 0.6033653846153846\n",
      "depth 5, learners 300, score 0.6049679487179487\n",
      "depth 5, learners 400, score 0.6030448717948718\n",
      "depth 5, learners 500, score 0.6000801282051282\n",
      "depth 5, learners 600, score 0.6052083333333333\n",
      "depth 5, learners 700, score 0.6060897435897437\n",
      "depth 5, learners 800, score 0.5959935897435897\n",
      "depth 5, learners 900, score 0.602323717948718\n",
      "depth 5, learners 1000, score 0.6050480769230769\n",
      "depth 10, learners 100, score 0.6204326923076924\n",
      "depth 10, learners 200, score 0.6403044871794872\n",
      "depth 10, learners 300, score 0.6435096153846154\n",
      "depth 10, learners 400, score 0.6350160256410255\n",
      "depth 10, learners 500, score 0.637099358974359\n",
      "depth 10, learners 600, score 0.6440705128205129\n",
      "depth 10, learners 700, score 0.6432692307692307\n",
      "depth 10, learners 800, score 0.6382211538461539\n",
      "depth 10, learners 900, score 0.6451121794871795\n",
      "depth 10, learners 1000, score 0.643349358974359\n",
      "depth 15, learners 100, score 0.6169070512820514\n",
      "depth 15, learners 200, score 0.6381410256410256\n",
      "depth 15, learners 300, score 0.6399839743589744\n",
      "depth 15, learners 400, score 0.6419871794871794\n",
      "depth 15, learners 500, score 0.6416666666666666\n",
      "depth 15, learners 600, score 0.6483173076923077\n",
      "depth 15, learners 700, score 0.6443910256410257\n",
      "depth 15, learners 800, score 0.6503205128205128\n",
      "depth 15, learners 900, score 0.6461538461538462\n",
      "depth 15, learners 1000, score 0.6541666666666666\n",
      "depth 20, learners 100, score 0.6426282051282052\n",
      "depth 20, learners 200, score 0.6362980769230769\n",
      "depth 20, learners 300, score 0.6325320512820513\n",
      "depth 20, learners 400, score 0.6357371794871796\n",
      "depth 20, learners 500, score 0.6504807692307693\n",
      "depth 20, learners 600, score 0.6420673076923077\n",
      "depth 20, learners 700, score 0.6474358974358974\n",
      "depth 20, learners 800, score 0.6503205128205127\n",
      "depth 20, learners 900, score 0.657371794871795\n",
      "depth 20, learners 1000, score 0.6369391025641026\n",
      "depth 25, learners 100, score 0.617948717948718\n",
      "depth 25, learners 200, score 0.6372596153846154\n",
      "depth 25, learners 300, score 0.6555288461538462\n",
      "depth 25, learners 400, score 0.6448717948717948\n",
      "depth 25, learners 500, score 0.6552083333333334\n",
      "depth 25, learners 600, score 0.6544871794871796\n",
      "depth 25, learners 700, score 0.6532852564102565\n",
      "depth 25, learners 800, score 0.6402243589743589"
     ]
    }
   ],
   "source": [
    "# actual import mfcc from FV\n",
    "import numpy as np\n",
    "import random as random\n",
    "import scipy.stats as stats\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import zero_one_loss\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(labels, n_folds=8, shuffle=True, random_state=1)\n",
    "for d in range(1, 11):\n",
    "    for l in range(1, 11):\n",
    "        depth = d*5\n",
    "        learners = l*100\n",
    "        rf = RandomForestClassifier(n_estimators = learners, max_depth = depth, warm_start = False)\n",
    "        score = np.average(cross_val_score(rf, mfcc, labels, cv=skf, n_jobs=1))\n",
    "        print('depth {}, learners {}, score {}'.format(depth, learners, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth 5, learners 100, train data accuracy 0.8675, test accuracy 0.53\n",
      "depth 5, learners 200, train data accuracy 0.8775, test accuracy 0.52\n",
      "depth 5, learners 300, train data accuracy 0.8725, test accuracy 0.525\n",
      "depth 5, learners 400, train data accuracy 0.87625, test accuracy 0.54\n",
      "depth 5, learners 500, train data accuracy 0.88, test accuracy 0.535\n",
      "depth 5, learners 600, train data accuracy 0.88125, test accuracy 0.555\n",
      "depth 5, learners 700, train data accuracy 0.87375, test accuracy 0.53\n",
      "depth 5, learners 800, train data accuracy 0.87625, test accuracy 0.53\n",
      "depth 5, learners 900, train data accuracy 0.88, test accuracy 0.505\n",
      "depth 5, learners 1000, train data accuracy 0.8775, test accuracy 0.52\n",
      "depth 10, learners 100, train data accuracy 1.0, test accuracy 0.56\n",
      "depth 10, learners 200, train data accuracy 1.0, test accuracy 0.59\n",
      "depth 10, learners 300, train data accuracy 1.0, test accuracy 0.6\n",
      "depth 10, learners 400, train data accuracy 1.0, test accuracy 0.58\n",
      "depth 10, learners 500, train data accuracy 1.0, test accuracy 0.57\n",
      "depth 10, learners 600, train data accuracy 1.0, test accuracy 0.565\n",
      "depth 10, learners 700, train data accuracy 1.0, test accuracy 0.585\n",
      "depth 10, learners 800, train data accuracy 1.0, test accuracy 0.575\n",
      "depth 10, learners 900, train data accuracy 1.0, test accuracy 0.6\n",
      "depth 10, learners 1000, train data accuracy 1.0, test accuracy 0.61\n",
      "depth 15, learners 100, train data accuracy 1.0, test accuracy 0.545\n",
      "depth 15, learners 200, train data accuracy 1.0, test accuracy 0.57\n",
      "depth 15, learners 300, train data accuracy 1.0, test accuracy 0.57\n",
      "depth 15, learners 400, train data accuracy 1.0, test accuracy 0.61\n",
      "depth 15, learners 500, train data accuracy 1.0, test accuracy 0.58\n",
      "depth 15, learners 600, train data accuracy 1.0, test accuracy 0.57\n",
      "depth 15, learners 700, train data accuracy 1.0, test accuracy 0.58\n",
      "depth 15, learners 800, train data accuracy 1.0, test accuracy 0.59\n",
      "depth 15, learners 900, train data accuracy 1.0, test accuracy 0.605\n",
      "depth 15, learners 1000, train data accuracy 1.0, test accuracy 0.59\n",
      "depth 20, learners 100, train data accuracy 1.0, test accuracy 0.565\n",
      "depth 20, learners 200, train data accuracy 1.0, test accuracy 0.595\n",
      "depth 20, learners 300, train data accuracy 1.0, test accuracy 0.595\n",
      "depth 20, learners 400, train data accuracy 1.0, test accuracy 0.595\n",
      "depth 20, learners 500, train data accuracy 1.0, test accuracy 0.59\n",
      "depth 20, learners 600, train data accuracy 1.0, test accuracy 0.59\n",
      "depth 20, learners 700, train data accuracy 1.0, test accuracy 0.59\n",
      "depth 20, learners 800, train data accuracy 1.0, test accuracy 0.595\n",
      "depth 20, learners 900, train data accuracy 1.0, test accuracy 0.6\n",
      "depth 20, learners 1000, train data accuracy 1.0, test accuracy 0.585\n",
      "depth 25, learners 100, train data accuracy 1.0, test accuracy 0.59\n",
      "depth 25, learners 200, train data accuracy 1.0, test accuracy 0.575\n",
      "depth 25, learners 300, train data accuracy 1.0, test accuracy 0.57\n",
      "depth 25, learners 400, train data accuracy 1.0, test accuracy 0.6\n",
      "depth 25, learners 500, train data accuracy 1.0, test accuracy 0.615\n",
      "depth 25, learners 600, train data accuracy 1.0, test accuracy 0.59\n",
      "depth 25, learners 700, train data accuracy 1.0, test accuracy 0.575\n",
      "depth 25, learners 800, train data accuracy 1.0, test accuracy 0.575\n",
      "depth 25, learners 900, train data accuracy 1.0, test accuracy 0.625\n",
      "depth 25, learners 1000, train data accuracy 1.0, test accuracy 0.58\n",
      "depth 30, learners 100, train data accuracy 1.0, test accuracy 0.555\n",
      "depth 30, learners 200, train data accuracy 1.0, test accuracy 0.61\n",
      "depth 30, learners 300, train data accuracy 1.0, test accuracy 0.595\n",
      "depth 30, learners 400, train data accuracy 1.0, test accuracy 0.57\n",
      "depth 30, learners 500, train data accuracy 1.0, test accuracy 0.595\n",
      "depth 30, learners 600, train data accuracy 1.0, test accuracy 0.62\n",
      "depth 30, learners 700, train data accuracy 1.0, test accuracy 0.605\n",
      "depth 30, learners 800, train data accuracy 1.0, test accuracy 0.59\n",
      "depth 30, learners 900, train data accuracy 1.0, test accuracy 0.585\n",
      "depth 30, learners 1000, train data accuracy 1.0, test accuracy 0.61\n",
      "depth 35, learners 100, train data accuracy 1.0, test accuracy 0.59\n",
      "depth 35, learners 200, train data accuracy 1.0, test accuracy 0.585\n",
      "depth 35, learners 300, train data accuracy 1.0, test accuracy 0.59\n",
      "depth 35, learners 400, train data accuracy 1.0, test accuracy 0.6\n",
      "depth 35, learners 500, train data accuracy 1.0, test accuracy 0.59\n",
      "depth 35, learners 600, train data accuracy 1.0, test accuracy 0.59\n",
      "depth 35, learners 700, train data accuracy 1.0, test accuracy 0.58\n",
      "depth 35, learners 800, train data accuracy 1.0, test accuracy 0.595\n",
      "depth 35, learners 900, train data accuracy 1.0, test accuracy 0.59\n",
      "depth 35, learners 1000, train data accuracy 1.0, test accuracy 0.605\n",
      "depth 40, learners 100, train data accuracy 1.0, test accuracy 0.6\n",
      "depth 40, learners 200, train data accuracy 1.0, test accuracy 0.56\n",
      "depth 40, learners 300, train data accuracy 1.0, test accuracy 0.605\n",
      "depth 40, learners 400, train data accuracy 1.0, test accuracy 0.595\n",
      "depth 40, learners 500, train data accuracy 1.0, test accuracy 0.6\n",
      "depth 40, learners 600, train data accuracy 1.0, test accuracy 0.615\n",
      "depth 40, learners 700, train data accuracy 1.0, test accuracy 0.565\n",
      "depth 40, learners 800, train data accuracy 1.0, test accuracy 0.58\n",
      "depth 40, learners 900, train data accuracy 1.0, test accuracy 0.59\n",
      "depth 40, learners 1000, train data accuracy 1.0, test accuracy 0.61\n",
      "depth 45, learners 100, train data accuracy 1.0, test accuracy 0.585\n",
      "depth 45, learners 200, train data accuracy 1.0, test accuracy 0.59\n",
      "depth 45, learners 300, train data accuracy 1.0, test accuracy 0.585\n",
      "depth 45, learners 400, train data accuracy 1.0, test accuracy 0.58\n",
      "depth 45, learners 500, train data accuracy 1.0, test accuracy 0.605\n",
      "depth 45, learners 600, train data accuracy 1.0, test accuracy 0.595\n",
      "depth 45, learners 700, train data accuracy 1.0, test accuracy 0.59\n",
      "depth 45, learners 800, train data accuracy 1.0, test accuracy 0.595\n",
      "depth 45, learners 900, train data accuracy 1.0, test accuracy 0.585\n",
      "depth 45, learners 1000, train data accuracy 1.0, test accuracy 0.59\n",
      "depth 50, learners 100, train data accuracy 1.0, test accuracy 0.605\n",
      "depth 50, learners 200, train data accuracy 1.0, test accuracy 0.565\n",
      "depth 50, learners 300, train data accuracy 1.0, test accuracy 0.57\n",
      "depth 50, learners 400, train data accuracy 1.0, test accuracy 0.57\n",
      "depth 50, learners 500, train data accuracy 1.0, test accuracy 0.58\n",
      "depth 50, learners 600, train data accuracy 1.0, test accuracy 0.6\n",
      "depth 50, learners 700, train data accuracy 1.0, test accuracy 0.595\n",
      "depth 50, learners 800, train data accuracy 1.0, test accuracy 0.585\n",
      "depth 50, learners 900, train data accuracy 1.0, test accuracy 0.595\n",
      "depth 50, learners 1000, train data accuracy 1.0, test accuracy 0.585\n"
     ]
    }
   ],
   "source": [
    "# actual import mfcc from FV\n",
    "import numpy as np\n",
    "import random as random\n",
    "import scipy.stats as stats\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import zero_one_loss\n",
    "\n",
    "for d in range(1, 11):\n",
    "    for l in range(1, 11):\n",
    "        depth = d*5\n",
    "        learners = l*100\n",
    "        rf = RandomForestClassifier(n_estimators = learners, max_depth = depth, warm_start = False)\n",
    "        rf.fit(trX,trY) # NOTE DATA ORIENTATION\n",
    "        print('depth {}, learners {}, train data accuracy {}, test accuracy {}'.format(depth, learners, rf.score(trX, trY), rf.score(teX, teY)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
