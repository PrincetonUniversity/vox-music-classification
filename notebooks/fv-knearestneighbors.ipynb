{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Random Forest multiclass regression with default (3, 3) parameter FV on only the MFCC features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.io as spio\n",
    "import numpy as np\n",
    "from os.path import join, isdir, isfile\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DATA_DIR = '../generated-fv'\n",
    "# 'file_name' 'class_name' 'class' 'eng' 'mfc' 'chroma' 't'\n",
    "# 'keystrength' 'brightness' 'zerocross' 'roughness' 'inharmonic' 'hcdf'\n",
    "#\n",
    "FVs = join(DATA_DIR, 'FV3-3.mat')\n",
    "LBs = join(DATA_DIR, 'LB.mat')\n",
    "if not isfile(FVs) or not isfile(LBs):\n",
    "    print('Generating Fisher Vectors')\n",
    "    !matlab -nodisplay -nosplash -nodesktop -r \"run('../tools/FV_concat.m');exit;\"\n",
    "else:\n",
    "    print('Using existing FVs')\n",
    "\n",
    "mfcc = np.transpose(spio.loadmat(FVs)['../generated-fv/FV3-3'])\n",
    "labels = spio.loadmat(LBs)['../generated-fv/LB'][0]\n",
    "N = mfcc.shape[0]\n",
    "\n",
    "p = np.random.permutation(N)\n",
    "mfcc = mfcc[p]\n",
    "labels = labels[p]\n",
    "\n",
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FVs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8a3f73faf777>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmfcc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFVs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'../generated-fv/FV3-3'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLBs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'../generated-fv/LB'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmfcc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'FVs' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import scipy.io as spio\n",
    "import numpy as np\n",
    "from os.path import join, isdir, isfile\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "mfcc = np.transpose(spio.loadmat(FVs)['../generated-fv/FV3-3'])\n",
    "labels = spio.loadmat(LBs)['../generated-fv/LB'][0]\n",
    "N = mfcc.shape[0]\n",
    "\n",
    "p = np.random.permutation(N)\n",
    "mfcc = mfcc[p]\n",
    "labels = labels[p]\n",
    "\n",
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trN = int(0.8 * N)\n",
    "teN = N - trN\n",
    "trX, trY = mfcc[:trN], labels[:trN]\n",
    "teX, teY = mfcc[-teN:], labels[-teN:]\n",
    "len(set(trY))\n",
    "\n",
    "means = np.mean(trX, axis=0)\n",
    "stddevs = np.std(trX, axis=0)\n",
    "\n",
    "def summary(x):\n",
    "    return '[{:.4f}, {:.4f}]'.format(np.ndarray.min(x), np.ndarray.max(x))\n",
    "print('means in range', summary(means))\n",
    "print('std in range', summary(stddevs))\n",
    "\n",
    "# Whitened data\n",
    "def adjust(x): return (x - means[None, :]) / stddevs[None, :]\n",
    "trXadj = adjust(trX)\n",
    "teXadj = adjust(teX)\n",
    "\n",
    "print('norm. means in range', summary(np.mean(trXadj, axis=0)))\n",
    "print('norm. std in range', summary(np.std(trXadj, axis=0)))\n",
    "trX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth 5, learners 100, train data accuracy 0.8675, test accuracy 0.53\n",
      "depth 5, learners 200, train data accuracy 0.8775, test accuracy 0.52\n",
      "depth 5, learners 300, train data accuracy 0.8725, test accuracy 0.525\n",
      "depth 5, learners 400, train data accuracy 0.87625, test accuracy 0.54\n",
      "depth 5, learners 500, train data accuracy 0.88, test accuracy 0.535\n",
      "depth 5, learners 600, train data accuracy 0.88125, test accuracy 0.555\n",
      "depth 5, learners 700, train data accuracy 0.87375, test accuracy 0.53\n",
      "depth 5, learners 800, train data accuracy 0.87625, test accuracy 0.53\n",
      "depth 5, learners 900, train data accuracy 0.88, test accuracy 0.505\n",
      "depth 5, learners 1000, train data accuracy 0.8775, test accuracy 0.52\n",
      "depth 10, learners 100, train data accuracy 1.0, test accuracy 0.56\n",
      "depth 10, learners 200, train data accuracy 1.0, test accuracy 0.59\n",
      "depth 10, learners 300, train data accuracy 1.0, test accuracy 0.6\n",
      "depth 10, learners 400, train data accuracy 1.0, test accuracy 0.58\n",
      "depth 10, learners 500, train data accuracy 1.0, test accuracy 0.57\n",
      "depth 10, learners 600, train data accuracy 1.0, test accuracy 0.565\n",
      "depth 10, learners 700, train data accuracy 1.0, test accuracy 0.585\n",
      "depth 10, learners 800, train data accuracy 1.0, test accuracy 0.575\n",
      "depth 10, learners 900, train data accuracy 1.0, test accuracy 0.6\n",
      "depth 10, learners 1000, train data accuracy 1.0, test accuracy 0.61\n",
      "depth 15, learners 100, train data accuracy 1.0, test accuracy 0.545\n",
      "depth 15, learners 200, train data accuracy 1.0, test accuracy 0.57\n",
      "depth 15, learners 300, train data accuracy 1.0, test accuracy 0.57\n",
      "depth 15, learners 400, train data accuracy 1.0, test accuracy 0.61\n",
      "depth 15, learners 500, train data accuracy 1.0, test accuracy 0.58\n",
      "depth 15, learners 600, train data accuracy 1.0, test accuracy 0.57\n",
      "depth 15, learners 700, train data accuracy 1.0, test accuracy 0.58\n",
      "depth 15, learners 800, train data accuracy 1.0, test accuracy 0.59\n",
      "depth 15, learners 900, train data accuracy 1.0, test accuracy 0.605\n",
      "depth 15, learners 1000, train data accuracy 1.0, test accuracy 0.59\n",
      "depth 20, learners 100, train data accuracy 1.0, test accuracy 0.565\n",
      "depth 20, learners 200, train data accuracy 1.0, test accuracy 0.595\n",
      "depth 20, learners 300, train data accuracy 1.0, test accuracy 0.595\n",
      "depth 20, learners 400, train data accuracy 1.0, test accuracy 0.595\n",
      "depth 20, learners 500, train data accuracy 1.0, test accuracy 0.59\n",
      "depth 20, learners 600, train data accuracy 1.0, test accuracy 0.59\n",
      "depth 20, learners 700, train data accuracy 1.0, test accuracy 0.59\n",
      "depth 20, learners 800, train data accuracy 1.0, test accuracy 0.595\n",
      "depth 20, learners 900, train data accuracy 1.0, test accuracy 0.6\n",
      "depth 20, learners 1000, train data accuracy 1.0, test accuracy 0.585\n",
      "depth 25, learners 100, train data accuracy 1.0, test accuracy 0.59\n",
      "depth 25, learners 200, train data accuracy 1.0, test accuracy 0.575\n",
      "depth 25, learners 300, train data accuracy 1.0, test accuracy 0.57\n",
      "depth 25, learners 400, train data accuracy 1.0, test accuracy 0.6\n",
      "depth 25, learners 500, train data accuracy 1.0, test accuracy 0.615\n",
      "depth 25, learners 600, train data accuracy 1.0, test accuracy 0.59\n",
      "depth 25, learners 700, train data accuracy 1.0, test accuracy 0.575\n",
      "depth 25, learners 800, train data accuracy 1.0, test accuracy 0.575\n",
      "depth 25, learners 900, train data accuracy 1.0, test accuracy 0.625\n",
      "depth 25, learners 1000, train data accuracy 1.0, test accuracy 0.58\n",
      "depth 30, learners 100, train data accuracy 1.0, test accuracy 0.555\n",
      "depth 30, learners 200, train data accuracy 1.0, test accuracy 0.61\n",
      "depth 30, learners 300, train data accuracy 1.0, test accuracy 0.595\n",
      "depth 30, learners 400, train data accuracy 1.0, test accuracy 0.57\n",
      "depth 30, learners 500, train data accuracy 1.0, test accuracy 0.595\n",
      "depth 30, learners 600, train data accuracy 1.0, test accuracy 0.62\n",
      "depth 30, learners 700, train data accuracy 1.0, test accuracy 0.605\n",
      "depth 30, learners 800, train data accuracy 1.0, test accuracy 0.59\n",
      "depth 30, learners 900, train data accuracy 1.0, test accuracy 0.585\n",
      "depth 30, learners 1000, train data accuracy 1.0, test accuracy 0.61\n",
      "depth 35, learners 100, train data accuracy 1.0, test accuracy 0.59\n",
      "depth 35, learners 200, train data accuracy 1.0, test accuracy 0.585\n",
      "depth 35, learners 300, train data accuracy 1.0, test accuracy 0.59\n",
      "depth 35, learners 400, train data accuracy 1.0, test accuracy 0.6\n",
      "depth 35, learners 500, train data accuracy 1.0, test accuracy 0.59\n",
      "depth 35, learners 600, train data accuracy 1.0, test accuracy 0.59\n",
      "depth 35, learners 700, train data accuracy 1.0, test accuracy 0.58\n",
      "depth 35, learners 800, train data accuracy 1.0, test accuracy 0.595\n",
      "depth 35, learners 900, train data accuracy 1.0, test accuracy 0.59\n",
      "depth 35, learners 1000, train data accuracy 1.0, test accuracy 0.605\n",
      "depth 40, learners 100, train data accuracy 1.0, test accuracy 0.6\n",
      "depth 40, learners 200, train data accuracy 1.0, test accuracy 0.56\n",
      "depth 40, learners 300, train data accuracy 1.0, test accuracy 0.605\n",
      "depth 40, learners 400, train data accuracy 1.0, test accuracy 0.595\n",
      "depth 40, learners 500, train data accuracy 1.0, test accuracy 0.6\n",
      "depth 40, learners 600, train data accuracy 1.0, test accuracy 0.615\n",
      "depth 40, learners 700, train data accuracy 1.0, test accuracy 0.565\n",
      "depth 40, learners 800, train data accuracy 1.0, test accuracy 0.58\n",
      "depth 40, learners 900, train data accuracy 1.0, test accuracy 0.59\n",
      "depth 40, learners 1000, train data accuracy 1.0, test accuracy 0.61\n",
      "depth 45, learners 100, train data accuracy 1.0, test accuracy 0.585\n",
      "depth 45, learners 200, train data accuracy 1.0, test accuracy 0.59\n",
      "depth 45, learners 300, train data accuracy 1.0, test accuracy 0.585\n",
      "depth 45, learners 400, train data accuracy 1.0, test accuracy 0.58\n",
      "depth 45, learners 500, train data accuracy 1.0, test accuracy 0.605\n",
      "depth 45, learners 600, train data accuracy 1.0, test accuracy 0.595\n",
      "depth 45, learners 700, train data accuracy 1.0, test accuracy 0.59\n",
      "depth 45, learners 800, train data accuracy 1.0, test accuracy 0.595\n",
      "depth 45, learners 900, train data accuracy 1.0, test accuracy 0.585\n",
      "depth 45, learners 1000, train data accuracy 1.0, test accuracy 0.59\n",
      "depth 50, learners 100, train data accuracy 1.0, test accuracy 0.605\n",
      "depth 50, learners 200, train data accuracy 1.0, test accuracy 0.565\n",
      "depth 50, learners 300, train data accuracy 1.0, test accuracy 0.57\n",
      "depth 50, learners 400, train data accuracy 1.0, test accuracy 0.57\n",
      "depth 50, learners 500, train data accuracy 1.0, test accuracy 0.58\n",
      "depth 50, learners 600, train data accuracy 1.0, test accuracy 0.6\n",
      "depth 50, learners 700, train data accuracy 1.0, test accuracy 0.595\n",
      "depth 50, learners 800, train data accuracy 1.0, test accuracy 0.585\n",
      "depth 50, learners 900, train data accuracy 1.0, test accuracy 0.595\n",
      "depth 50, learners 1000, train data accuracy 1.0, test accuracy 0.585\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# actual import mfcc from FV\n",
    "import numpy as np\n",
    "import random as random\n",
    "import scipy.stats as stats\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import zero_one_loss\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "neighbors = 5\n",
    "neigh = KNeighborsClassifier(n_neighbors=neighbors)\n",
    "neigh.fit(trX, trY)         \n",
    "print('neighbors {}, train data accuracy {}, test accuracy {}'.format(neighbors, neigh.score(trX, trY), neigh.score(teX, teY)))\n",
    "\n",
    "#for d in range(1, 11):\n",
    "#    for l in range(1, 11):\n",
    "#        depth = d*5\n",
    "#        learners = l*100\n",
    "#        rf = RandomForestClassifier(n_estimators = learners, max_depth = depth, warm_start = False)\n",
    "#        rf.fit(trX,trY) # NOTE DATA ORIENTATION\n",
    "#        print('depth {}, learners {}, train data accuracy {}, test accuracy {}'.format(depth, learners, rf.score(trX, trY), rf.score(teX, teY)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reg.fit(trXadj, trY)\n",
    "print('train data accuracy {} test accuracy {}'.format(reg.score(trXadj, trY), reg.score(teXadj, teY)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reg.fit(pcaX, trY)\n",
    "print('train data accuracy {} test accuracy {}'.format(reg.score(pcaX, trY), reg.score(pca.transform(teX), teY)))\n",
    "# interesting, training went up... try different PCA var exp values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Random-restart softmax\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "reg = LogisticRegressionCV(multi_class='multinomial', solver='lbfgs', max_iter=5000, n_jobs=8)\n",
    "reg.fit(trX, trY)\n",
    "print('train data accuracy {} test accuracy {}'.format(reg.score(trX, trY), reg.score(teX, teY)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
