{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adaboost Decision Stumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing FVs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import scipy.io as spio\n",
    "import numpy as np\n",
    "from os.path import join, isdir, isfile\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DATA_DIR = '../data'\n",
    "# 'file_name' 'class_name' 'class' 'eng' 'mfc' 'chroma' 't'\n",
    "# 'keystrength' 'brightness' 'zerocross' 'roughness' 'inharmonic' 'hcdf'\n",
    "#\n",
    "\n",
    "FVs = join(DATA_DIR, 'FV.mat')\n",
    "LBs = join(DATA_DIR, 'LB.mat')\n",
    "if not isfile(FVs) or not isfile(LBs):\n",
    "    print('Generating Fisher Vectors')\n",
    "    !matlab -nodisplay -nosplash -nodesktop -r \"run('../tools/FV_concat.m');exit;\"\n",
    "else:\n",
    "    print('Using existing FVs')\n",
    "\n",
    "mfcc = np.transpose(spio.loadmat(FVs)['FV'])\n",
    "labels = spio.loadmat(LBs)['LB'][0]\n",
    "\n",
    "height = mfcc.shape[0]\n",
    "width = mfcc.shape[1]\n",
    "w = int(width/2)\n",
    "kernelized = np.zeros((height, w))\n",
    "\n",
    "for i in range(height):\n",
    "    for j in range(w):\n",
    "        kernelized[i, j] = mfcc[i, j]\n",
    "        #kernelized[i, width+j] = mfcc[i,j]*mfcc[i, j]\n",
    "mfcc = kernelized\n",
    "\n",
    "N = mfcc.shape[0]\n",
    "\n",
    "p = np.random.permutation(N)\n",
    "mfcc = mfcc[p]\n",
    "labels = labels[p]\n",
    "\n",
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "means in range [-0.0193, 0.0077]\n",
      "std in range [0.0244, 0.0613]\n",
      "norm. means in range [-0.0000, 0.0000]\n",
      "norm. std in range [1.0000, 1.0000]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(800, 480)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trN = int(0.8 * N)\n",
    "teN = N - trN\n",
    "trX, trY = mfcc[:trN], labels[:trN]\n",
    "teX, teY = mfcc[-teN:], labels[-teN:]\n",
    "len(set(trY))\n",
    "\n",
    "means = np.mean(trX, axis=0)\n",
    "stddevs = np.std(trX, axis=0)\n",
    "\n",
    "def summary(x):\n",
    "    return '[{:.4f}, {:.4f}]'.format(np.ndarray.min(x), np.ndarray.max(x))\n",
    "print('means in range', summary(means))\n",
    "print('std in range', summary(stddevs))\n",
    "\n",
    "# Whitened data\n",
    "def adjust(x): return (x - means[None, :]) / stddevs[None, :]\n",
    "trXadj = adjust(trX)\n",
    "teXadj = adjust(teX)\n",
    "\n",
    "print('norm. means in range', summary(np.mean(trXadj, axis=0)))\n",
    "print('norm. std in range', summary(np.std(trXadj, axis=0)))\n",
    "trX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_classes 10\n",
      "numStumps 2, train data accuracy 0.2475, test accuracy 0.24\n",
      "n_classes 10\n",
      "numStumps 4, train data accuracy 0.2975, test accuracy 0.25\n",
      "n_classes 10\n",
      "numStumps 6, train data accuracy 0.28875, test accuracy 0.255\n",
      "n_classes 10\n",
      "numStumps 8, train data accuracy 0.30125, test accuracy 0.255\n",
      "n_classes 10\n",
      "numStumps 10, train data accuracy 0.295, test accuracy 0.25\n",
      "n_classes 10\n",
      "numStumps 12, train data accuracy 0.29125, test accuracy 0.25\n",
      "n_classes 10\n",
      "numStumps 14, train data accuracy 0.30625, test accuracy 0.255\n",
      "n_classes 10\n",
      "numStumps 16, train data accuracy 0.30375, test accuracy 0.255\n",
      "n_classes 10\n",
      "numStumps 18, train data accuracy 0.28, test accuracy 0.27\n",
      "n_classes 10\n",
      "numStumps 20, train data accuracy 0.28, test accuracy 0.27\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "for n in range(1, 11):\n",
    "    numStumps = 2*n\n",
    "    stumps = AdaBoostClassifier(n_estimators=numStumps, base_estimator=DecisionTreeClassifier(max_depth=1))\n",
    "    stumps.fit(trX, trY)\n",
    "    print('n_classes {}'.format(stumps.n_classes_))\n",
    "    print('numStumps {}, train data accuracy {}, test accuracy {}'.format(numStumps, stumps.score(trX, trY), stumps.score(teX, teY)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reg.fit(trXadj, trY)\n",
    "print('train data accuracy {} test accuracy {}'.format(reg.score(trXadj, trY), reg.score(teXadj, teY)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reg.fit(pcaX, trY)\n",
    "print('train data accuracy {} test accuracy {}'.format(reg.score(pcaX, trY), reg.score(pca.transform(teX), teY)))\n",
    "# interesting, training went up... try different PCA var exp values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Random-restart softmax\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "reg = LogisticRegressionCV(multi_class='multinomial', solver='lbfgs', max_iter=5000, n_jobs=8)\n",
    "reg.fit(trX, trY)\n",
    "print('train data accuracy {} test accuracy {}'.format(reg.score(trX, trY), reg.score(teX, teY)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
